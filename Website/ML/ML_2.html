<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Machine Learning</title>
    <link rel="stylesheet" href="../css/bootstrap.min.css">
    <link rel="stylesheet" href="../css/styles.css">
    <link href='https://fonts.googleapis.com/css?family=Oxygen:400,300,700' rel='stylesheet' type='text/css'>
  </head>
<body>
  <!-- START OF HEADER -->
  <header>
    <nav id="header-nav" class="navbar navbar-default">
      <div class="container">
        <div class="navbar-header">
          <a href="index.html" class="pull-left visible-md visible-lg">
            <div id="logo-img" alt="Logo Image"></div>
          </a>
          <div class="navbar-brand">
            <a href="index.html"><h1>UNIQUEDU</h1></a>
            <p>
              <span class="hidden-xs">The uniqueness in knowledge we provide is more than you expect.</span>
              <span class="visible-xs">The uniqueness in knowledge we <br>provide is more than you expect.</span>
            </p>
          </div>
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#collapsable-nav" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <div id="collapsable-nav" class="collapse navbar-collapse">
          <ul id="nav-list" class="nav navbar-nav navbar-right">
            <li class="visible-xs">
              <a href="../HOME.html">
                <span class="glyphicon glyphicon-home"></span>Home
              </a>
            </li>
            <li>
              <a href="../BLOGS.html">
                <span class="glyphicon glyphicon-book"></span><br class="hidden-xs"> Blogs
              </a>
            </li>
            <li>
              <a href="../about.html">
                <span class="glyphicon glyphicon-info-sign"></span><br class="hidden-xs"> About Us
              </a>
            </li>
            <li>
              <a href="../Join.html">
                <span class="glyphicon glyphicon-user"></span><br class="hidden-xs"> Join Us
              </a>
            </li>
            <li id="phone" class="hidden-xs">
              <a href="tel:+918595641819">
                <span>+918595641819</span>
              </a>
              <div>* Contact</div>
            </li>
          </ul>
        </div>
      </div>
    </nav>
  </header>
  <div id="call-btn" class="visible-xs">
    <a class="btn" href="tel:+918595641819">
      <span class="glyphicon glyphicon-earphone"></span>
      +918595641819
    </a>
  </div>
  <div id="xs-deliver" class="text-center visible-xs">* Contact</div>
  <!-- END OF HEADER -->
  <div id="main-content" class="container">
    <h2 id="education" class="text-center">Linear Regressing with one Variable</h2>
    <section class="C">
      <h4 id="education">
        Greetings! This is <b>Parv Arora</b> and I have done certifications in Machine Learning. So, in this series of  blogs, I am going to give you a full tutorial on machine learning. Our next topic is Linear Regression in one variable and for that we have to first understand what is Linear Regression.<br><br>

        <b><u>Linear Regression</u></b><br><br>
        Linear regression is perhaps one of the most well known and well understood algorithms in statistics and machine learning. Linear regression attempts to model the relationship between two variables by fitting a linear equation to observed data. One variable is considered to be an explanatory variable, and the other is considered to be a dependent variable. For example, a modeler might want to relate the weights of individuals to their heights using a linear regression model.<br><br>
        Before attempting to fit a linear model to observed data, a modeler should first determine whether or not there is a relationship between the variables of interest. This does not necessarily imply that one variable causes the other (for example, higher SAT scores do not cause higher college grades), but that there is some significant association between the two variables. A scatterplot can be a helpful tool in determining the strength of the relationship between two variables. If there appears to be no association between the proposed explanatory and dependent variables (i.e., the scatterplot does not indicate any increasing or decreasing trends), then fitting a linear regression model to the data probably will not provide a useful model. A valuable numerical measure of association between two variables is the correlation coefficient, which is a value between -1 and 1 indicating the strength of the association of the observed data for the two variables.<br><br>
        A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable. The slope of the line is b, and a is the intercept (the value of y when x = 0).<br><br>
      </h4>
      <img class="img visible-xs" src="5.jpg" alt="launch">
      <div style="text-align: center;">
        <img class="hidden-xs" src="5.jpg" alt="launch" width="600" height="300">
      </div>
      <h4 id="education">
        <br><b><u>Linear Regressing with one Variable</u></b><br><br>
        To establish notation for future use, we’ll use x<sup>(i)</sup> to denote the “input” variables (living area in this example), also called input features, and y<sup>(i)</sup> to denote the “output” or target variable that we are trying to predict (price). A pair (x<sup>(i)</sup>, y<sup>(i)</sup>) is called a training example, and the dataset that we’ll be using to learn—a list of m training examples (x<sup>(i)</sup>, y<sup>(i)</sup>); i = 1, . . . , m — is called a training set. Note that the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation. We will also use X to denote the space of input values, and Y to denote the space of output values. In this example, X = Y = ℝ.<br><br> 
        To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. Seen pictorially, the process is therefore like this:<br><br>
      </h4>
      <img class="img visible-xs" src="6.jpg" alt="launch">
      <div style="text-align: center;">
        <img class="hidden-xs" src="6.jpg" alt="launch" width="600" height="300">
      </div>
      <h4 id="education">
        <br>When the target variable that we’re trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem. When y can take on only a small number of discrete values (such as if, given the living area, we wanted to predict if a dwelling is a house or an apartment, say), we call it a classification problem.<br><br>
        
        <b><u>Cost Function</u></b><br><br>
        We can measure the accuracy of our hypothesis function by using a cost function. This takes an average difference (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's and the actual output y's.<br><br>
      </h4>
      <img class="img visible-xs" src="7.jpg" alt="launch">
      <div style="text-align: center;">
        <img class="hidden-xs" src="7.jpg" alt="launch" width="600" height="300">
      </div>
      <h4 id="education">
        <br>To break it apart, it is (1/2) xˉ where xˉ is the mean of the squares of h<sub>θ</sub>(x<sub>i</sub>) - y<sub>i</sub>, or the difference between the predicted value and the actual value.<br>
        This function is otherwise called the "Squared error function", or "Mean squared error". The mean is halved (1/2) as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the (1/2) term.<br><br>
        
        <b><u>Gradient Descent</u></b><br><br>
        So we have our hypothesis function and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in the hypothesis function. That's where gradient descent comes in.<br><br>
        Imagine that we graph our hypothesis function based on its fields θ<sub>0</sub> and θ<sub>i</sub>1 (actually we are graphing the cost function as a function of the parameter estimates). We are not graphing x and y itself, but the parameter range of our hypothesis function and the cost resulting from selecting a particular set of parameters.<br><br>
        We put θ<sub>0</sub> on the x axis and θ<sub>1</sub> on the y axis, with the cost function on the vertical z axis. The points on our graph will be the result of the cost function using our hypothesis with those specific theta parameters. The graph below depicts such a setup.<br><br>
      </h4>
      <img class="img visible-xs" src="8.jpg" alt="launch">
      <div style="text-align: center;">
        <img class="hidden-xs" src="8.jpg" alt="launch" width="600" height="300">
      </div>
      <h4 id="education">
        <br>We will know that we have succeeded when our cost function is at the very bottom of the pits in our graph, i.e. when its value is the minimum. The red arrows show the minimum points in the graph.<br><br>
        The way we do this is by taking the derivative (the tangential line to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent. The size of each step is determined by the parameter α, which is called the learning rate.<br><br> 
        For example, the distance between each 'star' in the graph above represents a step determined by our parameter α. A smaller α would result in a smaller step and a larger α results in a larger step. The direction in which the step is taken is determined by the partial derivative of J(θ<sub>0</sub>, θ<sub>1</sub>). Depending on where one starts on the graph, one could end up at different points. The image above shows us two different starting points that end up in two different places. <br><br>
        The gradient descent algorithm is:<br>
        repeat until convergence:<br>
        <b>θ<sub>j</sub>:=θ<sub>j</sub>−α(∂/∂θ<sub>j</sub>)J(θ<sub>0</sub>,θ<sub>1</sub>)</b>
        where<br>
        j=0,1 represents the feature index number.<br><br>
        At each iteration j, one should simultaneously update the parameters θ1,θ2,...,θn. Updating a specific parameter prior to calculating another one on the j<sup>(th)</sup> iteration would yield to a wrong implementation.<br><br> 
        So, this is all about Linear regression in one variable. Thank you to be so patient. I hope you gained a brief knowledge about the topic.<br><br>
        Be alert guys I will post more on Machine Learning. Feel free to provide feedback guys to help me improve my content.
      </h4>

          <h4 id="education" style="text-align: right">
            <b>• PARV ARORA</b><br>
          </h4>
    </section>
    <div class="next">
      <a href="ML_3.html">
        <button class="button" type="button"><b>Next ></b></button>
      </a>
    </div>
    <div class="previous">
      <a href="ML_1.html">
        <button class="button2" type="button"><b>< Previous</b></button>
      </a>
    </div>
    <div style="padding-top: 70px;color: DarkSlateGrey;">
      <!-- begin wwww.htmlcommentbox.com -->
      <div id="HCB_comment_box"><a href="http://www.htmlcommentbox.com">Widget</a> is loading comments...</div>
      <link rel="stylesheet" type="text/css" href="https://www.htmlcommentbox.com/static/skins/bootstrap/twitter-bootstrap.css?v=0" />
      <script type="text/javascript" id="hcb"> /*<!--*/ if(!window.hcb_user){hcb_user={};} (function(){var s=document.createElement("script"), l=hcb_user.PAGE || (""+window.location).replace(/'/g,"%27"), h="https://www.htmlcommentbox.com";s.setAttribute("type","text/javascript");s.setAttribute("src", h+"/jread?page="+encodeURIComponent(l).replace("+","%2B")+"&mod=%241%24wq1rdBcg%24Sz0SmeaMQmmgsm6PwOpm2%2F"+"&opts=16862&num=10&ts=1621539441105");if (typeof s!="undefined") document.getElementsByTagName("head")[0].appendChild(s);})(); /*-->*/ </script>
      <!-- end www.htmlcommentbox.com -->
    </div>
  </div>

  <!--START OF FOOTER-->
  <footer class="panel-footer">
    <div class="container">
      <div class="row">
        <section id="hours" class="col-sm-4">
          <span>Hours : </span><br>
          Monday - Saturday : 10:00am - 8:00pm<br>
          Sunday : 12:00pm - 6:00pm<br>
          <hr class="visible-xs">
        </section>
        <section id="address" class="col-sm-4">
          <span>Address : </span><br>
          Faridabad, Haryana<br>
          Developed by<br> "PRAJWAL SHARMA" & "AYUSH RANA"<br>
          <p>* Please call before coming...!</p>
          <hr class="visible-xs">
        </section>
        <section id="testimonials" class="col-sm-4">
          <p>Email-Id : uniquedu.3017@gmail.com</p>
          <p>Contact : +918595641819</p><br>
          Instagram : <a href="https://www.instagram.com/uniquedu.3017/">@uniquedu.3017</a><br><br>
          <p>"If you want to write blog than mail us...!"</p>
        </section>
      </div>
      <div class="text-center">&copy; UniquEdu.co.in</div>
    </div>
  </footer>
  <!--END OF FOOTER-->

  <!-- jQuery (Bootstrap JS plugins depend on it) -->
  <script src="../js/jquery-2.1.4.min.js"></script>
  <script src="../js/bootstrap.min.js"></script>
  <script src="../../js/script.js"></script>
</body>
</html>
